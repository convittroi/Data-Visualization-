{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Select features according to the k highest scores (F-test)\n",
    "#In case of several features, we will use the F-test to select the import features.\n",
    "##### Split the Data \n",
    "# Split the data into the features and the target (Temperature)\n",
    "data_y=data.Temperature\n",
    "data_x=data.drop(columns='Temperature')\n",
    "idx=np.arange(data.shape[0])\n",
    "#Setting the `random_state` to ensure that a \"random\" process will output the same result everytime, which makes your code reproducible. This is useful if you want to train two or more models on the same data and compare them.\n",
    "# fixing the seed for random state so that we can have the same training & test sets anytime\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test=train_test_split(data_x, data_y,idx, test_size=0.2, random_state=1) # 80% training and 20% test\n",
    "#X_train has all the features except temperature and y_train has the corresponding temperature for those features. In the supervised machine learning we first provide the model with input and the associated output and then we check with a new input.\n",
    "# Initialize the train/test split for the model. Mark the values belonging to the train set as -1 and the test set as 0\n",
    "split_index = [-1 if i in idx_train else 0 for i in idx]\n",
    "ps = PredefinedSplit(test_fold=split_index)\n",
    "X_train.shape ,X_test.shape, y_train.shape, y_test.shape\n",
    "##### Data Normalization\n",
    "#Scale all the features in the same scale to prevent one feature dominates the others & then neglected by ML Model.\n",
    "#Using `MinMaxScaler()` to scale the data to range [0,1]\n",
    "scaled_X_train=MinMaxScaler().fit_transform(X_train)\n",
    "scaled_X_test=MinMaxScaler().fit_transform(X_test)\n",
    "scaled_X_train=pd.DataFrame(scaled_X_train, columns=X_train.columns)  # Shift the data to a DataFrame\n",
    "scaled_X_test=pd.DataFrame(scaled_X_test, columns=X_test.columns)\n",
    "# # We can also use the StandardScaler to transform the data to have a mean of 0 and a standard deviation of 1\n",
    "# # For example:\n",
    "# data_std=StandardScaler().fit_transform(data)\n",
    "# data_std=pd.DataFrame(data_std, columns=data.columns)\n",
    "# data_std.describe().round(3)\n",
    "##### Training the features selection model\n",
    "#[`SelecKBest()` Function](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) : Select features according to the k highest scores.  \n",
    "selection=SelectKBest(f_regression, k=5) # Select the 5 best features\n",
    "selection.fit(scaled_X_train, y_train)\n",
    "selection.scores_\n",
    "cols = selection.get_support(indices=True)\n",
    "cols\n",
    "#â†’ So, the best features are Sky_clearness, Tem_max, Tem_min, Humidity, and Pressure  \n",
    "#Then, we make a new training data, testing data and the data_x\n",
    "scaled_X_train_selected=scaled_X_train.iloc[:,cols]\n",
    "scaled_X_test_selected=scaled_X_test.iloc[:,cols]\n",
    "X_train_selected=X_train.iloc[:,cols]\n",
    "X_test_selected=X_test.iloc[:,cols]\n",
    "data_x_selected=data_x.iloc[:,cols]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
