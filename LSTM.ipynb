{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for LSTM  \n",
    "Because of our dataset is stationary, hence we need to transform the time series as supervised data. This can be done by shifting the time\n",
    "series data and then compare the shifted time series data with the original one. In our case, we will do 7 different lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sky_clearness</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Tem_max</th>\n",
       "      <th>Tem_min</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Wind Speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-27</th>\n",
       "      <td>0.61</td>\n",
       "      <td>21.82</td>\n",
       "      <td>26.18</td>\n",
       "      <td>16.95</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.83</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-28</th>\n",
       "      <td>0.63</td>\n",
       "      <td>20.19</td>\n",
       "      <td>25.62</td>\n",
       "      <td>14.91</td>\n",
       "      <td>11.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.75</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-29</th>\n",
       "      <td>0.52</td>\n",
       "      <td>20.86</td>\n",
       "      <td>26.10</td>\n",
       "      <td>15.41</td>\n",
       "      <td>12.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.66</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-30</th>\n",
       "      <td>0.32</td>\n",
       "      <td>21.31</td>\n",
       "      <td>25.77</td>\n",
       "      <td>17.84</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.02</td>\n",
       "      <td>100.85</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>0.13</td>\n",
       "      <td>16.73</td>\n",
       "      <td>18.66</td>\n",
       "      <td>14.86</td>\n",
       "      <td>9.95</td>\n",
       "      <td>7.22</td>\n",
       "      <td>101.17</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sky_clearness  Temperature  Tem_max  Tem_min  Humidity  \\\n",
       "Date                                                                 \n",
       "2023-11-27           0.61        21.82    26.18    16.95     12.76   \n",
       "2023-11-28           0.63        20.19    25.62    14.91     11.23   \n",
       "2023-11-29           0.52        20.86    26.10    15.41     12.27   \n",
       "2023-11-30           0.32        21.31    25.77    17.84     14.16   \n",
       "2023-12-01           0.13        16.73    18.66    14.86      9.95   \n",
       "\n",
       "            Precipitation  Pressure  Wind Speed  \n",
       "Date                                             \n",
       "2023-11-27           0.00    100.83        1.37  \n",
       "2023-11-28           0.00    100.75        2.01  \n",
       "2023-11-29           0.00    100.66        1.26  \n",
       "2023-11-30           2.02    100.85        2.52  \n",
       "2023-12-01           7.22    101.17        3.74  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('datasets.csv',\n",
    "                 header=None, sep=',', skiprows=17, na_values='-999', \n",
    "                 names=['Year','Month','Day','Sky_clearness','Temperature','Tem_max','Tem_min','Humidity','Precipitation','Pressure','Wind Speed'])\n",
    "\n",
    "data['Date'] = pd.to_datetime(data[['Year', 'Month', 'Day']],errors='ignore')\n",
    "'''The reason why we have to use errors=\"ignore\" is because not all the dates we are parsing that are in the correct format.\n",
    "If we use errors=\"coerce\" then any dates that cannot be converted will be set to NaT.'''\n",
    "data=data.drop(columns=['Year','Month','Day'])\n",
    "data=data.set_index('Date')\n",
    "data=data.dropna()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp=data.Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_lstm(df, look_back):\n",
    "    for i in range(1,look_back+1):\n",
    "        df['lag_{}'.format(i)] = df['Temperature'].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "      <td>21.01</td>\n",
       "      <td>17.86</td>\n",
       "      <td>17.85</td>\n",
       "      <td>17.09</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-09</th>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "      <td>21.01</td>\n",
       "      <td>17.86</td>\n",
       "      <td>17.85</td>\n",
       "      <td>17.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-10</th>\n",
       "      <td>23.58</td>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "      <td>21.01</td>\n",
       "      <td>17.86</td>\n",
       "      <td>17.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-11</th>\n",
       "      <td>23.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "      <td>21.01</td>\n",
       "      <td>17.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-12</th>\n",
       "      <td>20.30</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "      <td>21.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-13</th>\n",
       "      <td>20.53</td>\n",
       "      <td>20.30</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-14</th>\n",
       "      <td>23.42</td>\n",
       "      <td>20.53</td>\n",
       "      <td>20.30</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.03</td>\n",
       "      <td>21.87</td>\n",
       "      <td>20.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temperature  lag_1  lag_2  lag_3  lag_4  lag_5  lag_6  lag_7\n",
       "Date                                                                    \n",
       "1990-01-08        21.87  20.60  19.73  21.01  17.86  17.85  17.09  18.62\n",
       "1990-01-09        23.03  21.87  20.60  19.73  21.01  17.86  17.85  17.09\n",
       "1990-01-10        23.58  23.03  21.87  20.60  19.73  21.01  17.86  17.85\n",
       "1990-01-11        23.13  23.58  23.03  21.87  20.60  19.73  21.01  17.86\n",
       "1990-01-12        20.30  23.13  23.58  23.03  21.87  20.60  19.73  21.01\n",
       "1990-01-13        20.53  20.30  23.13  23.58  23.03  21.87  20.60  19.73\n",
       "1990-01-14        23.42  20.53  20.30  23.13  23.58  23.03  21.87  20.60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back=7\n",
    "data_lstm=prepare_data_lstm(data_temp.to_frame(), look_back)\n",
    "data_lstm.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.87, 20.6 , 19.73, ..., 17.85, 17.09, 18.62],\n",
       "       [23.03, 21.87, 20.6 , ..., 17.86, 17.85, 17.09],\n",
       "       [23.58, 23.03, 21.87, ..., 21.01, 17.86, 17.85],\n",
       "       ...,\n",
       "       [20.86, 20.19, 21.82, ..., 21.77, 21.64, 20.39],\n",
       "       [21.31, 20.86, 20.19, ..., 21.43, 21.77, 21.64],\n",
       "       [16.73, 21.31, 20.86, ..., 21.53, 21.43, 21.77]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data to a numpy array for the LSTM model\n",
    "data_lstm_np= data_lstm.to_numpy()\n",
    "data_lstm_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we proceed to split our supervised data into training and test set. For this case, I am going to use the last month as test data. But before that, we need to normalize the value of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (optional)\n",
    "scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "data_lstm_scaled=scaler.fit_transform(data_lstm_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, it's essential to flip in the horizontal direction (lag_7 -> lag_1) since the LSTM model gets the updated results until reaching the most close value to the current time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into input and output\n",
    "X_lstm=np.flip(data_lstm_scaled[:,1:],axis=1) \n",
    "y_lstm=data_lstm_scaled[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12350, 7), (31, 7), (12350,), (31,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "split_index = int(len(data_lstm[:'2023-10'])) # Test data from 2023-11-01\n",
    "X_lstm_train=X_lstm[:split_index]\n",
    "X_lstm_test=X_lstm[split_index:]\n",
    "\n",
    "y_lstm_train=y_lstm[:split_index]\n",
    "y_lstm_test=y_lstm[split_index:]\n",
    "\n",
    "X_lstm_train.shape, X_lstm_test.shape, y_lstm_train.shape, y_lstm_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12350, 7, 1), (31, 7, 1), (12350, 1), (31, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure that the our data has an extra dimension for LSTM model\n",
    "X_lstm_train = np.expand_dims(X_lstm_train, axis=-1)\n",
    "X_lstm_test = np.expand_dims(X_lstm_test, axis=-1)\n",
    "\n",
    "y_lstm_train = np.expand_dims(y_lstm_train, axis=-1)\n",
    "y_lstm_test = np.expand_dims(y_lstm_test, axis=-1)\n",
    "\n",
    "X_lstm_train.shape, X_lstm_test.shape, y_lstm_train.shape, y_lstm_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.32131049],\n",
       "        [ 0.33273219],\n",
       "        [ 0.33754133],\n",
       "        [ 0.26059513],\n",
       "        [ 0.22813345],\n",
       "        [ 0.1746318 ],\n",
       "        [ 0.19206492]],\n",
       "\n",
       "       [[ 0.33273219],\n",
       "        [ 0.33754133],\n",
       "        [ 0.26059513],\n",
       "        [ 0.22813345],\n",
       "        [ 0.1746318 ],\n",
       "        [ 0.19206492],\n",
       "        [ 0.15840096]],\n",
       "\n",
       "       [[ 0.33754133],\n",
       "        [ 0.26059513],\n",
       "        [ 0.22813345],\n",
       "        [ 0.1746318 ],\n",
       "        [ 0.19206492],\n",
       "        [ 0.15840096],\n",
       "        [ 0.16561467]],\n",
       "\n",
       "       [[ 0.26059513],\n",
       "        [ 0.22813345],\n",
       "        [ 0.1746318 ],\n",
       "        [ 0.19206492],\n",
       "        [ 0.15840096],\n",
       "        [ 0.16561467],\n",
       "        [ 0.23715059]],\n",
       "\n",
       "       [[ 0.22813345],\n",
       "        [ 0.1746318 ],\n",
       "        [ 0.19206492],\n",
       "        [ 0.15840096],\n",
       "        [ 0.16561467],\n",
       "        [ 0.23715059],\n",
       "        [ 0.29546138]],\n",
       "\n",
       "       [[ 0.1746318 ],\n",
       "        [ 0.19206492],\n",
       "        [ 0.15840096],\n",
       "        [ 0.16561467],\n",
       "        [ 0.23715059],\n",
       "        [ 0.29546138],\n",
       "        [ 0.31469793]],\n",
       "\n",
       "       [[ 0.19206492],\n",
       "        [ 0.15840096],\n",
       "        [ 0.16561467],\n",
       "        [ 0.23715059],\n",
       "        [ 0.29546138],\n",
       "        [ 0.31469793],\n",
       "        [ 0.21190261]],\n",
       "\n",
       "       [[ 0.15840096],\n",
       "        [ 0.16561467],\n",
       "        [ 0.23715059],\n",
       "        [ 0.29546138],\n",
       "        [ 0.31469793],\n",
       "        [ 0.21190261],\n",
       "        [-0.01232341]],\n",
       "\n",
       "       [[ 0.16561467],\n",
       "        [ 0.23715059],\n",
       "        [ 0.29546138],\n",
       "        [ 0.31469793],\n",
       "        [ 0.21190261],\n",
       "        [-0.01232341],\n",
       "        [ 0.18364893]],\n",
       "\n",
       "       [[ 0.23715059],\n",
       "        [ 0.29546138],\n",
       "        [ 0.31469793],\n",
       "        [ 0.21190261],\n",
       "        [-0.01232341],\n",
       "        [ 0.18364893],\n",
       "        [ 0.31830478]],\n",
       "\n",
       "       [[ 0.29546138],\n",
       "        [ 0.31469793],\n",
       "        [ 0.21190261],\n",
       "        [-0.01232341],\n",
       "        [ 0.18364893],\n",
       "        [ 0.31830478],\n",
       "        [ 0.32912534]],\n",
       "\n",
       "       [[ 0.31469793],\n",
       "        [ 0.21190261],\n",
       "        [-0.01232341],\n",
       "        [ 0.18364893],\n",
       "        [ 0.31830478],\n",
       "        [ 0.32912534],\n",
       "        [ 0.32912534]],\n",
       "\n",
       "       [[ 0.21190261],\n",
       "        [-0.01232341],\n",
       "        [ 0.18364893],\n",
       "        [ 0.31830478],\n",
       "        [ 0.32912534],\n",
       "        [ 0.32912534],\n",
       "        [ 0.18845807]],\n",
       "\n",
       "       [[-0.01232341],\n",
       "        [ 0.18364893],\n",
       "        [ 0.31830478],\n",
       "        [ 0.32912534],\n",
       "        [ 0.32912534],\n",
       "        [ 0.18845807],\n",
       "        [-0.2245266 ]],\n",
       "\n",
       "       [[ 0.18364893],\n",
       "        [ 0.31830478],\n",
       "        [ 0.32912534],\n",
       "        [ 0.32912534],\n",
       "        [ 0.18845807],\n",
       "        [-0.2245266 ],\n",
       "        [-0.21851518]],\n",
       "\n",
       "       [[ 0.31830478],\n",
       "        [ 0.32912534],\n",
       "        [ 0.32912534],\n",
       "        [ 0.18845807],\n",
       "        [-0.2245266 ],\n",
       "        [-0.21851518],\n",
       "        [-0.08085362]],\n",
       "\n",
       "       [[ 0.32912534],\n",
       "        [ 0.32912534],\n",
       "        [ 0.18845807],\n",
       "        [-0.2245266 ],\n",
       "        [-0.21851518],\n",
       "        [-0.08085362],\n",
       "        [-0.15118726]],\n",
       "\n",
       "       [[ 0.32912534],\n",
       "        [ 0.18845807],\n",
       "        [-0.2245266 ],\n",
       "        [-0.21851518],\n",
       "        [-0.08085362],\n",
       "        [-0.15118726],\n",
       "        [-0.18364893]],\n",
       "\n",
       "       [[ 0.18845807],\n",
       "        [-0.2245266 ],\n",
       "        [-0.21851518],\n",
       "        [-0.08085362],\n",
       "        [-0.15118726],\n",
       "        [-0.18364893],\n",
       "        [-0.19927863]],\n",
       "\n",
       "       [[-0.2245266 ],\n",
       "        [-0.21851518],\n",
       "        [-0.08085362],\n",
       "        [-0.15118726],\n",
       "        [-0.18364893],\n",
       "        [-0.19927863],\n",
       "        [-0.11872558]],\n",
       "\n",
       "       [[-0.21851518],\n",
       "        [-0.08085362],\n",
       "        [-0.15118726],\n",
       "        [-0.18364893],\n",
       "        [-0.19927863],\n",
       "        [-0.11872558],\n",
       "        [-0.12353472]],\n",
       "\n",
       "       [[-0.08085362],\n",
       "        [-0.15118726],\n",
       "        [-0.18364893],\n",
       "        [-0.19927863],\n",
       "        [-0.11872558],\n",
       "        [-0.12353472],\n",
       "        [-0.13435528]],\n",
       "\n",
       "       [[-0.15118726],\n",
       "        [-0.18364893],\n",
       "        [-0.19927863],\n",
       "        [-0.11872558],\n",
       "        [-0.12353472],\n",
       "        [-0.13435528],\n",
       "        [-0.00871656]],\n",
       "\n",
       "       [[-0.18364893],\n",
       "        [-0.19927863],\n",
       "        [-0.11872558],\n",
       "        [-0.12353472],\n",
       "        [-0.13435528],\n",
       "        [-0.00871656],\n",
       "        [ 0.06642621]],\n",
       "\n",
       "       [[-0.19927863],\n",
       "        [-0.11872558],\n",
       "        [-0.12353472],\n",
       "        [-0.13435528],\n",
       "        [-0.00871656],\n",
       "        [ 0.06642621],\n",
       "        [ 0.07424106]],\n",
       "\n",
       "       [[-0.11872558],\n",
       "        [-0.12353472],\n",
       "        [-0.13435528],\n",
       "        [-0.00871656],\n",
       "        [ 0.06642621],\n",
       "        [ 0.07424106],\n",
       "        [ 0.05380222]],\n",
       "\n",
       "       [[-0.12353472],\n",
       "        [-0.13435528],\n",
       "        [-0.00871656],\n",
       "        [ 0.06642621],\n",
       "        [ 0.07424106],\n",
       "        [ 0.05380222],\n",
       "        [ 0.05981365]],\n",
       "\n",
       "       [[-0.13435528],\n",
       "        [-0.00871656],\n",
       "        [ 0.06642621],\n",
       "        [ 0.07424106],\n",
       "        [ 0.05380222],\n",
       "        [ 0.05981365],\n",
       "        [ 0.07724677]],\n",
       "\n",
       "       [[-0.00871656],\n",
       "        [ 0.06642621],\n",
       "        [ 0.07424106],\n",
       "        [ 0.05380222],\n",
       "        [ 0.05981365],\n",
       "        [ 0.07724677],\n",
       "        [-0.0207394 ]],\n",
       "\n",
       "       [[ 0.06642621],\n",
       "        [ 0.07424106],\n",
       "        [ 0.05380222],\n",
       "        [ 0.05981365],\n",
       "        [ 0.07724677],\n",
       "        [-0.0207394 ],\n",
       "        [ 0.01953712]],\n",
       "\n",
       "       [[ 0.07424106],\n",
       "        [ 0.05380222],\n",
       "        [ 0.05981365],\n",
       "        [ 0.07724677],\n",
       "        [-0.0207394 ],\n",
       "        [ 0.01953712],\n",
       "        [ 0.04658852]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LSTM model\n",
    "n_neurons=64\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_neurons, input_shape=(look_back, 1)))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.fit(X_lstm_train, y_lstm_train, epochs=300, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model training, we can use the model to predict the test data. After that, we need preprocess the prediction because we have normalized the data before. Hence, we basically need to inverse the scale back to the original so that we can compare the prediction result with the original time series data.\n",
    "pred_temp_lstm=model_lstm.predict(X_lstm_test)\n",
    "pred_data=scaler.inverse_transform(np.concatenate((pred_temp_lstm, X_lstm_test.reshape(-1,look_back)), axis=1))[:,0]\n",
    "true_data=scaler.inverse_transform(np.concatenate((y_lstm_test, X_lstm_test.reshape(-1,look_back)), axis=1))[:,0]\n",
    "df_lstm=pd.DataFrame({'True':true_data, 'Predicted':pred_data}, index=data_lstm['2023-11-01':].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
